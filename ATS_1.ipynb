{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "84f89cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.5)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 6.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.8.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script nltk.exe is installed in 'C:\\Users\\caleb\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "# pip install nltk --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cd833eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx2txt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c6ee5ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the applicant and job descriptions\n",
    "# Set filenames to resume and jd variables\n",
    "# List of text to store resumes and job descriptions\n",
    "resumedocx_1 = \"Caleb Picker Resume draft 16 July 09 2023.docx\"\n",
    "resumedocx_2 = \"Caleb Picker Resume draft 18 July 09 2023.docx\"\n",
    "resumedocx_3 = \"Caleb Picker Resume draft 17 July 09 2023 - full.docx\"\n",
    "resumedocx_4 = \"Caleb Picker Resume draft 19 July 10 2023.docx\"\n",
    "\n",
    "resumes = [docx2txt.process(file) for file in [resumedocx_1, resumedocx_2, resumedocx_3, resumedocx_4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d9a54864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMport job description\n",
    "job_descriptions = [\n",
    "    docx2txt.process(\"Data Engineer.docx\"),\n",
    "    docx2txt.process(\"Senior Data Scientist.docx\"),\n",
    "    docx2txt.process(\"Sr Data Engineer.docx\"),\n",
    "    docx2txt.process(\"Sr Data Engineer Quality.docx\"),\n",
    "    docx2txt.process(\"Data Analyst.docx\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8b31b71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\caleb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\caleb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\caleb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Donwload NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize Stemmer and lemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# List of stopwords\n",
    "stopwords_set = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5c717948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Process Text function (to be used in final function)\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text into individual words\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and perform stemming/lemmatization\n",
    "    processed_tokens = [stemmer.stem(lemmatizer.lemmatize(token)) for token in tokens if token.lower() not in stopwords_set]\n",
    "    \n",
    "    # Join the processed tokens back into a string\n",
    "    processed_text = ' '.join(processed_tokens)\n",
    "    \n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e59d7c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of text to store resume and job desription\n",
    "def count_matrix_fun(resume,jd):\n",
    "    # Preprocess resume and job description\n",
    "    processed_resume = preprocess_text(resume)\n",
    "    processed_jd = preprocess_text(jd)\n",
    "    \n",
    "    text = [processed_resume,processed_jd]\n",
    "    # Count the number of words in the text matrix\n",
    "    cv = CountVectorizer()\n",
    "    count_matrix = cv.fit_transform(text)\n",
    "    \n",
    "    # Calculate cosine similarity similar to percent match\n",
    "    cos_sim = cosine_similarity(count_matrix)[0][1]\n",
    "    match = (cos_sim + 1)/2*100\n",
    "    match = round(match,2)\n",
    "    \n",
    "    return match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f395b8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare resumes to job descriptions\n",
    "def compare_resumes_to_job_descriptions(resumes, job_descriptions):\n",
    "    matrix = []\n",
    "    for i, resume_text in enumerate(resumes):\n",
    "        row = []\n",
    "        for j, jd_text in enumerate(job_descriptions):\n",
    "            match = count_matrix_fun(resume_text,jd_text)\n",
    "            row.append(match)\n",
    "        matrix.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(matrix, index =[f\"Resume {i+1}\" for i in range(len(resumes))],columns=[\"Job Description \"+str(j+1) for j in range(len(job_descriptions))])\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7afb886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resumes = [resume_1,resume_2,resume_3,resume_4]\n",
    "\n",
    "# for i, resume_text in enumerate(resumes):\n",
    "#    count_matrix_fun(resume_text,jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "84f93607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Job Description 1  Job Description 2  Job Description 3  \\\n",
      "Resume 1              64.09              66.85              64.09   \n",
      "Resume 2              66.70              67.34              66.61   \n",
      "Resume 3              63.84              65.64              63.81   \n",
      "Resume 4              67.58              70.51              67.49   \n",
      "\n",
      "          Job Description 4  Job Description 5  \n",
      "Resume 1              66.66              66.84  \n",
      "Resume 2              67.23              67.23  \n",
      "Resume 3              65.66              65.57  \n",
      "Resume 4              68.68              69.15  \n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = compare_resumes_to_job_descriptions(resumes, job_descriptions)\n",
    "\n",
    "print(similarity_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bb4b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
